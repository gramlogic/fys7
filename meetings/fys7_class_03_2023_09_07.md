* [ ] James Moll
* [ ] Owen 
* [ ] Chloe 
* [ ] Vega 
* [ ] Kaden 
* [ ] Huy 
* [ ] Makela 
* [ ] Bethany 
* [ ] Allison 
* [ ] Sebastian 
* [ ] Shaswat 
* [ ] Olivier
* [ ] Rafael

## Slaughterbots Discussion: Key Details

### Key detail
* Violence with violence.
* Kill fewer people or more people?


### Persuasive
* Kid on Factime with mom.
* Appeal to Pathos.
* Extrajudicial executions via slaughterbots.

* Scary for AI to decide.
* Before sentience.
* Possible with current technology.
* Removes risk to perpetrator.
* Would the legal system be able to keep up?

* Miniaturizing everything is a security problem, 
* Like buying a gun.
* Should this be controlled.
* Lockheed Martin wouldn't sell this.

* Mutually assured destruction.



### Off
* Not realistic that everyone would have one.
* Public announcement.


### Threat
* Anyone: single person could have the same effect as a large terrorist group.
* Harder to stop that.
* The threat it shows isn't what the AI is doing. It's what people are doing with it.
* Everyone has different thoughts/beliefs, so whose ideology is evil?
* Being created and release by a company that doesn't have a big picture.
* Would people be able to mass produce this on their own right now?
* Maybe could do it on your own. Can already 3-d print a drone.
* Once the technology exists, it can get out of box. (Nuclear, and ChatGPT)
* Relationship to Israel's Iron dome.

### Enemy
* Robots
* (Perspective switch, from perspective of the drone camera)
* Creator of the robot
* User of the robot
* Government (exposing corruption)
* Conflict between humans is creating a lot of death
* Social media
* Evil ideology
* Purposefully not the developers; more like the guy commercializing it.


### Mechanism of disaster
* Ollie in Edinburg
* The government 


### Audience
* People who are not necessarily against AI, but kind of neutral
* Not going to persuade people 
* Berkeley professor
* The developers of the technology. (We're not mad at you.)






